---
title: "Tidy (Art Historical) Data"
author: "Matthew Lincoln"
date: "September 23, 2015"
output: ioslides_presentation
---

```{r opts, message=FALSE, warning=FALSE, echo=FALSE}
library(knitr)
library(londonauctions)
library(dplyr)
library(ggplot2)
knitr::opts_chunk$set(message=FALSE, warning=FALSE, echo=FALSE)
```

# Making a tidy table

## What is tidy data?

1. One variable per column
1. One observation per row
1. Consistent data types
1. If you can't do 1 and 2, that means you need an extra table

## Why?

1. Make it easy to analyze at scale
2. Make it easy to share
3. Make it easy to recombine with other data

```{r raw_sales, include=FALSE}
messy_data <- data_frame(
  acq_no = c("1999.32", "1908.54", "1955.32", "1955.33"),
  artist_1 = c("Studio of Rembrandt", "Jan Vermeer", "Vermeer, Jan", "Hals, Frans"),
  artist_2 = c("possibly Govaert Flinck", NA, NA, NA),
  date = c("after 1636", "c. 1650", "c. 1655", "16220"),
  medium = c("oil on canvas", "oil on panel", "oil on canvas", "oil on canvas, relined"),
  tags = c("religious, portrait", "genre, woman", "woman, window, painting", "merry company")
)

clean_data_obj <- data_frame(
  acq_no = messy_data$acq_no,
  date = c(1636, 1650, 1655, 1620),
  date_qual = c("after", "circa", "circa", NA),
  medium = rep("oil", 4),
  support = c("canvas", "panel", "canvas", "canvas"),
  cons_note = c(NA, NA, NA, "relined")
)

clean_data_artist <- data_frame(
  acq_no = c("1999.32", "1999.32", "1908.54", "1955.32", "1955.33"),
  name = c("Rembrandt", "Govaert Flinck", "Jan Vermeer", "Jan Vermeer", "Frans Hals"),
  qualification = c("studio of", "possibly", NA, NA, NA)
)

clean_data_tags <- data_frame(
  acq_no = c("1999.32", "1999.32", "1908.54", "1908.54", "1955.32", "1955.32", "1955.32", "1955.33"),
  tag = c("religious", "portrait", "genre", "woman", "woman", "window", "painting", "merry_company")
)
```

## Messy (but well-intentioned!) data

```{r}
messy_data %>% kable()
```

- On the plus side, there is a unique ID column!

## One variable per column

```{r}
messy_data %>% kable()
```

- `artist_1`: first and last names combined; conditionals
- `date`: conditionals
- `medium`: medium and support combined; conditionals

## One observation per row

```{r}
messy_data %>% kable()
```

- `tags` and `artists` need to be their own tables

## Consistent types and values

```{r}
messy_data %>% kable()
```

- `date` has typos
- `date` could potentially be numeric

# Tidied data

## Objects

Three conceptual tables: objects, artist links, and tags.

```{r}
clean_data_obj %>% kable()
```

## Object-Artist

```{r}
clean_data_artist %>% kable()
```

## Object-Tags

```{r}
clean_data_tags %>% kable()
```

---

By separating out tables, we can be more flexible with the types of questions we can ask.

```{r, echo=TRUE}
# What paintings have the tag "woman"?
clean_data_obj %>% 
  inner_join(clean_data_tags, by = "acq_no") %>% 
  filter(tag == "woman") %>% kable()
```

---

```{r, echo = TRUE}
# When was each painter working?
clean_data_obj %>% 
  inner_join(clean_data_artist, by = "acq_no") %>%
  filter(is.na(qualification) | qualification != "studio of") %>% 
  ggplot(aes(x = name, y = date, color = date_qual)) + 
  geom_point(size = 5)
```

## Tips for Historical Datasets

- Use a structured vocabulary when there are a limited number of possible values for a column. This allows easier counting and better consistency across your data.
- Be consistent with date formats.
    - If you have day-level info for some entries, and only year level for others, think about putting in `1701-01-01`, or have separate columns for year, month, day.
    - Do some records have a start and end date? Have a `start_date` and `end_date`
- A loose "notes" column is fine, but if you find yourself frequently making a similar type of note (e.g. `citation`) then you probably need to make a new column just for that information.

## Tips for Historical Datasets II

- "Uncertain" values
    - `[?]` is not informative. What about: `illegible`, `unsubstantiated`, `approximate`?
    - Make an uncertainty vocabulary if you have to, so the terms are controlled, countable, and documented
    - Use separate columns liberally, e.g. `date`, `date_uncertainty`
- You can't document everything! If some tricky field is just not relevant enough to your research, then don't kill yourself trying to capture it with perfect specificity.
- **It is easy to recombine columns later. It is very hard to split them out.**

# Documenting tidy data

## Do it for future-you & for others

- You **will** forget what you did in a few months. Or even a few days. Docs will remind you.
- Docs make writing reports/articles easier
- Docs make your data reusable:
    - others won't have to guess at what a certain column means
    - or what decisions you made when recording it
    - or how to cite it
    - or if/how they may reuse it

## Show your work

- Describe what you made:
    - Keep a plain text doc in the same directory as your tables
    - Have a heading for each table
    - List every column name and describe what it means
        - Incl. list of possible values, relation to other tables as appropriate
- Document the process
    - Did you adapt this from another dataset? (incl. original data, or link)
    - Describe the transformations you made, including what software you used

# Sharing tidy data

## Flat Files, Not Live Servers

Omeka and the like are great for interactively communicating stories and selections from your research. They are not a storage and dissemination solution _in the long run_. Costly, fragile, limiting.

"Flat files" are decoupled from running software, and can be opened by a regular text editor. Someone without your original software has a better chance of recovering the information.

## Plaintext

- Use plain text file types for tables and docs (`.txt`, `.csv`, not `.xslx`)
    - Free
    - Somewhat more future-proof
    - Track-able
- Creating in Excel/Google Sheets is fine, you can export it
    - When saving in Excel, use `UTF-8` so that accents & special characters are preserved
    - Don't rely on meaningful formatting (colored cells, bold, italics, borders), because that won't be preserved
    - Save multiple versions

## Archive it

- Bundle data and documentation in the same directory and zip them.
- Distribute
    - Institutional repository (upload it with your dissertation)
    - Journal websites
    - [Zenodo](https://zenodo.org/)
    - [Git](https://git-scm.com/) (works great with all-text files - more and more libraries and journals will be moving towards this method for tracking file versions)

## Resources

- [See a tidy data example](https://github.com/mdlincoln/tidy-arth-data/tree/gh-pages/example_data)
- Database management
    - [Google Fusion Tables](https://www.google.com/fusiontables/)
    - [UCLA DH101: Data and Databases](http://dh101.humanities.ucla.edu/?page_id=93)
    - [Designing Databases for Historical Research](http://port.sas.ac.uk/mod/book/view.php?id=75) (great intro to relational DBs)
- Data cleaning with [OpenRefine](http://programminghistorian.org/lessons/cleaning-data-with-openrefine)
